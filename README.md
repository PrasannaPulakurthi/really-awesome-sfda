# Awesome Source‑Free Domain Adaptation (SFDA) [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://makeapullrequest.com)

Curated resources for Source‑Free Domain Adaptation (SFDA): methods that adapt using only a trained source model (no source data). Includes papers, code, datasets, benchmarks, and tutorials.
<!--lint disable awesome-github -->

## Contents
- [Papers](#papers)
- [Datasets & Benchmarks](#datasets--benchmarks)
- [Libraries & Tooling](#libraries--tooling)
- [Tutorials & Talks](#tutorials--talks)
- [Related](#related)

## Papers
- A Comprehensive Survey on Source-Free Domain Adaptation (TPAMI 2024) [paper](https://doi.org/10.1109/tpami.2024.3370978)
- GALA: Graph Diffusion-based Alignment with Jigsaw for Source-free Domain Adaptation (TPAMI 2024) [paper](https://doi.org/10.1109/tpami.2024.3416372)
- Neighborhood-Aware Mutual Information Maximization for Source-Free Domain Adaptation (TMM 2024) [paper](https://doi.org/10.1109/tmm.2024.3394971)
- ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation (WACV 2024) [paper](https://doi.org/10.1109/wacv57701.2024.00297)
- SF(DA)^2: Source-free Domain Adaptation Through the Lens of Data Augmentation (arXiv 2024) [arxiv](https://arxiv.org/abs/2403.10834)
- SepRep-Net: Multi-source Free Domain Adaptation via Model Separation and Reparameterization (arXiv 2024) [arxiv](https://arxiv.org/abs/2402.08249)
- Source-Free Domain Adaptation for RGB-D Semantic Segmentation with Vision Transformers (arXiv 2024) [arxiv](https://arxiv.org/pdf/2305.14269)
- Source-Free Domain Adaptation with Diffusion-Guided Source Data Generation (arXiv 2024) [arxiv](https://arxiv.org/abs/2402.04929)
- Source-Free Domain Adaptation with Frozen Multimodal Foundation Model (CVPR 2024) [paper](https://doi.org/10.1109/cvpr52733.2024.02238)
- Understanding and Improving Source-Free Domain Adaptation from a Theoretical Perspective (CVPR 2024) [paper](https://doi.org/10.1109/cvpr52733.2024.02694)
- Visually Source-Free Domain Adaptation via Adversarial Style Matching (TIP 2024) [paper](https://doi.org/10.1109/tip.2024.3353539)

## Methods — Open-set / Partial / Universal
<!-- Merged paper entries into Papers section above. Add non-paper resources here if needed. -->

## Tasks — Image Classification
<!-- Add non-paper resources here if applicable. -->

## Tasks — Semantic Segmentation
<!-- Add non-paper resources here if applicable. -->

## Datasets & Benchmarks
- DomainNet — multi‑domain classification benchmark.
- Office‑31 / Office‑Home — classic DA suites, widely reused in SFDA.
- VisDA‑2017 — synthetic→real; used by SFDA methods.

## Libraries & Tooling
- Add libraries and tooling here.

## Tutorials & Talks
- Add tutorials and talks here.

## Related
- Awesome Domain Adaptation — broader DA resources.

## Contributing
Please read [CONTRIBUTING.md](CONTRIBUTING.md). Use this entry format:

```
- [Title (Venue/Year)](https://example.com/paper) — one sentence summary. [code](https://example.com/code) [project](https://example.com/site)
```

Sorting policy:
- Sort entries alphabetically by title within each section.
